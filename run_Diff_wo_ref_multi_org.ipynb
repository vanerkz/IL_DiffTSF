{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28881,
     "status": "ok",
     "timestamp": 1666122413113,
     "user": {
      "displayName": "Van Koh",
      "userId": "15908915889656003541"
     },
     "user_tz": -480
    },
    "id": "C3VXRzTvtuO-",
    "outputId": "8a582d77-aa7f-4b90-e9d9-cb267ecb08fc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(model='Diff_TS', data='ETTh1', root_path='/home/uservan/Desktop/TS_Diff/datasets', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='model_parameters/ETTh1', seq_len=168, label_len=168, pred_len=24, enc_in=7, dec_in=7, c_out=7, d_model=256, d_ff=256, padding=0, distil=False, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=True, mix=True, cols=None, num_workers=8, itr=1, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='test', loss='mse', lradj='type1', use_amp=False, inverse=False, likeloss=True, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', lossregularizer=True, n_times=50, sampling=False, sampling_times=50, detail_freq='h')\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from exp.exp_NRU_RBN import Exp_NRU_RBN\n",
    "%matplotlib inline\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Diff_TS Forecasting')\n",
    "\n",
    "parser.add_argument('--model', type=str, default='Diff_TS',help='model of experiment, options: [NRU_RBN]')\n",
    "value=\"ETTh1\" #ETTh1,ETTm2,electrans,weather,exchange\n",
    "parser.add_argument('--data', type=str, default=value, help='data')\n",
    "parser.add_argument('--root_path', type=str, default=os.path.abspath('../')+'/datasets', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default=value+'.csv', help='data file')    #electrans.csv\n",
    "parser.add_argument('--features', type=str, default='M', help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h', help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default= 'model_parameters/'+value, help='location of model checkpoints')\n",
    "\n",
    "parser.add_argument('--seq_len', type=int, default=int(24*7), help='input sequence length of Informer encoder')\n",
    "parser.add_argument('--label_len', type=int, default=int(24*7) , help='start token length of Informer decoder')\n",
    "parser.add_argument('--pred_len', type=int, default=24, help='prediction sequence length')\n",
    "\n",
    "parser.add_argument('--enc_in', type=int, default=1, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=1, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=1, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=256, help='dimension of model')\n",
    "parser.add_argument('--d_ff', type=int, default=256, help='dimension of fcn')\n",
    "parser.add_argument('--padding', type=int, default=0, help='padding type')\n",
    "parser.add_argument('--distil', action='store_false', help='whether to use distilling in encoder, using this argument means not using distilling', default=False)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF', help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu',help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder',default=False)\n",
    "parser.add_argument('--do_predict', action='store_false', help='whether to predict unseen future data')\n",
    "parser.add_argument('--mix', action='store_false', help='use mix attention in generative decoder', default=True)\n",
    "parser.add_argument('--cols', type=str, nargs='+', help='certain cols from the data files as the input features')\n",
    "parser.add_argument('--num_workers', type=int, default=8, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=20, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=5, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test',help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse',help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1',help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "parser.add_argument('--inverse', action='store_true', help='inverse output data', default=False)\n",
    "parser.add_argument('--likeloss', action='store_true', help='likeloss', default=True)\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3',help='device ids of multile gpus')\n",
    "parser.add_argument('--lossregularizer', type=bool, default=True, help='Use loss regularizer')\n",
    "parser.add_argument('--n_times', type=int, default=50, help='diffusion steps')\n",
    "parser.add_argument('--sampling', type=bool, default=False, help='sampling of outcomes')\n",
    "parser.add_argument('--sampling_times', type=int, default=50, help='number of outcomes')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "data_parser = {\n",
    "    'exchange':{'data':'exchange_all.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'d'},\n",
    "    'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'h'},\n",
    "    'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'h'},\n",
    "    'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'h'},\n",
    "    'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'t'},\n",
    "    'weather':{'data':'weather.csv','T':'OT','M':[12,12,12],'S':[1,1,1],'MS':[12,12,1],'freqin':'h'},\n",
    "    'electrans':{'data':'electrans.csv','T':'OT','M':[316,316,316],'S':[1,1,1],'MS':[316,316,1],'freqin':'h'},\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "    data_info = data_parser[args.data]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T']\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]\n",
    "    args.freq=data_info['freqin']\n",
    "\n",
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(model='Diff_TS', data='electrans', root_path='/home/uservan/Desktop/TS_Diff/datasets', data_path='electrans.csv', features='M', target='OT', freq='h', checkpoints='model_parameters/electrans', seq_len=168, label_len=168, pred_len=24, enc_in=32, dec_in=32, c_out=32, d_model=256, d_ff=256, padding=0, distil=False, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=True, mix=True, cols=None, num_workers=8, itr=1, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='test', loss='mse', lradj='type1', use_amp=False, inverse=False, likeloss=True, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', lossregularizer=True, n_times=50, sampling=False, sampling_times=50, detail_freq='h')\n",
      "168\n",
      "96\n",
      "168\n",
      "96\n",
      "Use GPU: cuda:0\n",
      "Trainable Parameters:3919457\n",
      "Trainable Parameters:298016\n",
      ">>>>>>>start training later Diff_TS_168_96_delectrans_ftM_sl168_ll168_pl96_dm256_df256_ebtimeF_0_lossreg_True_n_times_100_ii_100>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 18149\n",
      "val 2369\n",
      "No File, Train new\n",
      "No EST File, Train new\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc895baea964175a714788dee37dd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test&train\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "Exp = Exp_NRU_RBN\n",
    "def runtrain(args):\n",
    "        mape_list=[]\n",
    "        mae_list=[]\n",
    "        rmse_list=[]\n",
    "        dtw_list=[]\n",
    "        res_list=[]\n",
    "        shape_list=[]\n",
    "        corr_list=[]\n",
    "        crps_list=[]\n",
    "        mse_list=[]\n",
    "        crps_varlist=[]\n",
    "        print(args.label_len)\n",
    "        print(args.pred_len)\n",
    "        index =args.model +\"_\"+str(args.label_len)+\"_\"+str(args.pred_len)\n",
    "        resultsMAE,resultsCRPS,resultsMSE=[],[],[]\n",
    "        mape_list,mae_list,rmse_list=[],[],[]\n",
    "        dtw_list,res_list,shape_list=[],[],[]\n",
    "        corr_list,crps_list,mse_list,crps_varlist=[],[],[],[]\n",
    "        for ii in range(args.itr):\n",
    "               \n",
    "                # setting record of experiments\n",
    "                setting = '{}_d{}_ft{}_sl{}_ll{}_pl{}_dm{}_df{}_eb{}_{}_lossreg_{}_n_times_{}_ii_{}'.format(\n",
    "                        index, args.data, args.features,args.seq_len, args.label_len, args.pred_len,\n",
    "                        args.d_model, args.d_ff,\n",
    "                        args.embed, 0,str(args.lossregularizer),args.n_times,args.reg)\n",
    "                \n",
    "                exp = Exp(args) # set experiments\n",
    "                print('>>>>>>>start training later {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "                _,tepochloss,tdataloss,tregloss,tvalepochloss,tvaldataloss,tvalregloss=exp.train(setting)\n",
    "                torch.cuda.empty_cache()\n",
    "                resultout,crpsret,sqtrue,sqpred,sigmaouts=exp.test(setting,True)\n",
    "                \n",
    "                mae,mse,rmse,mspe,shape =resultout\n",
    "\n",
    "                print(setting)\n",
    "                mse_list.append(mse)\n",
    "                mse_np=np.array(mse_list)\n",
    "                mae_list.append(mae)\n",
    "                mae_np=np.array(mae_list)\n",
    "                crps_list.append(np.mean(crpsret))\n",
    "                #crps_varlist.append(np.var(crpsret))\n",
    "                crps_np=np.array(crps_list)\n",
    "                #crps_varlist_np=np.array(crps_varlist)\n",
    "        \n",
    "                print(\"predlen:\"+str(args.pred_len)+\",CRPS_L:\"+str(len(crps_np))+\",AVE:\"+str(np.round(np.mean(crps_np),3))+\"±\"+str(np.round(np.std(crps_np),4)))\n",
    "                print(\"predlen:\"+str(args.pred_len)+\",MSE_L:\"+str(len(mse_np))+\",AVE:\"+str(np.round(np.mean(mse_np),3))+\"±\"+str(np.round(np.std(mse_np),4)))\n",
    "                print(\"predlen:\"+str(args.pred_len)+\",MAE_L:\"+str(len(mae_np))+\",AVE:\"+str(np.round(np.mean(mae_np),3))+\"±\"+str(np.round(np.std(mae_np),4)))\n",
    "                resultsCRPS.append(str(ii)+\"_\"+\"predlen:\"+str(args.pred_len)+\",CRPS_L:\"+str(len(crps_np))+\",AVE:\"+str(np.round(np.mean(crps_np),3))+\"±\"+str(np.round(np.std(crps_np),4)))\n",
    "                resultsMSE.append(str(ii)+\"_\"+\"predlen:\"+str(args.pred_len)+\",MSE_L:\"+str(len(mse_np))+\",AVE:\"+str(np.round(np.mean(mse_np),3))+\"±\"+str(np.round(np.std(mse_np),4)))\n",
    "                resultsMAE.append(str(ii)+\"_\"+\"predlen:\"+str(args.pred_len)+\",MAE_L:\"+str(len(mae_np))+\",AVE:\"+str(np.round(np.mean(mae_np),3))+\"±\"+str(np.round(np.std(mae_np),4)))\n",
    "                f= open(os.path.abspath('')+\"/results/\"+str(args.data)+\"/\"+str(args.pred_len)+\"_d_ff\"+str(args.d_ff)+\"_ntimes\"+str(args.n_times)+\"_\"+str(args.data)+\".txt\",\"w+\")\n",
    "                f.write(str(setting)+\"\\n\"+str(resultsCRPS) +\"\\n\"+str(resultsMSE)+\"\\n\"+str(resultsMAE))\n",
    "                f.close()\n",
    "                sqtrue=0\n",
    "                sqpred=0\n",
    "        torch.cuda.empty_cache()\n",
    "        return sqtrue,sqpred\n",
    "\n",
    "for nn in range(3,4):\n",
    "        valueindex=['ETTh1','exchange','ETTm2','electrans']\n",
    "        args.data =valueindex[nn]\n",
    "        args.checkpoints='model_parameters/'+valueindex[nn]\n",
    "        \n",
    "        data_parser = {\n",
    "        'exchange':{'data':'exchange_all.csv','T':'OT','M':[8,8,8],'S':[1,1,1],'MS':[8,8,1],'freqin':'d'},\n",
    "        'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'h'},\n",
    "        'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'h'},\n",
    "        'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'h'},\n",
    "        'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'t'},\n",
    "        'weather':{'data':'weather.csv','T':'OT','M':[12,12,12],'S':[1,1,1],'MS':[12,12,1],'freqin':'h'},\n",
    "        'electrans':{'data':'electrans.csv','T':'OT','M':[32,32,32],'S':[1,1,1],'MS':[321,321,1],'freqin':'h'},\n",
    "        }\n",
    "        if args.data in data_parser.keys():\n",
    "                data_info = data_parser[args.data]\n",
    "                args.data_path = data_info['data']\n",
    "                args.target = data_info['T']\n",
    "                args.enc_in, args.dec_in, args.c_out = data_info[args.features]\n",
    "                args.freq=data_info['freqin']\n",
    "        \n",
    "        args.detail_freq = args.freq\n",
    "        args.freq = args.freq[-1:]\n",
    "        print('Args in experiment:')\n",
    "        print(args)\n",
    "        for i in range(1,3,1):\n",
    "                torch.cuda.empty_cache()\n",
    "                fix_seed = 1\n",
    "                torch.manual_seed(fix_seed)\n",
    "                np.random.seed(fix_seed)\n",
    "                args.d_ff=256\n",
    "                args.d_model=256\n",
    "                args.reg=100\n",
    "                items= [[168,24],[168,96],[336,168],[720,336]] #for ETTh1\n",
    "                if i==2:\n",
    "                        args.batch_size=16\n",
    "                elif i>2:\n",
    "                        args.batch_size=8\n",
    "                else:\n",
    "                        args.batch_size=16    \n",
    "                args.n_times=100\n",
    "                args.label_len =items[i][0]\n",
    "                args.seq_len=args.label_len\n",
    "                args.pred_len =items[i][1]\n",
    "                print(args.label_len)\n",
    "                print(args.pred_len)\n",
    "                sqtrue,sqpred=runtrain(args)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNYamTAUmYDsZgII9uXX8CT",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1bcfz1OsVbD2yCIk1zcleV5paW0iaFtTg",
   "name": "",
   "version": ""
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "60461829a35a4f24414f6b9a81cb167855ac5d995cbf4b4b96212d9b44c21eb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
