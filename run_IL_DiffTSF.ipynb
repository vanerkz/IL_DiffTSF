{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28881,
     "status": "ok",
     "timestamp": 1666122413113,
     "user": {
      "displayName": "Van Koh",
      "userId": "15908915889656003541"
     },
     "user_tz": -480
    },
    "id": "C3VXRzTvtuO-",
    "outputId": "8a582d77-aa7f-4b90-e9d9-cb267ecb08fc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from exp.exp_IL_DiffTSF import Exp_IL_DiffTSF\n",
    "\n",
    "parser = argparse.ArgumentParser(description='IL_DiffTSF')\n",
    "\n",
    "parser.add_argument('--model', type=str, default='IL_DiffTSF')\n",
    "value=\"ETTh1\" #ETTh1,ETTm2,electrans,weather,exchange\n",
    "parser.add_argument('--data', type=str, default=value, help='data')\n",
    "parser.add_argument('--root_path', type=str, default=os.path.abspath('../')+'/datasets', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default=value+'.csv', help='data file')    #electrans.csv\n",
    "parser.add_argument('--features', type=str, default='M', help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h', help='15min or 1H or 1D')\n",
    "parser.add_argument('--checkpoints', type=str, default= 'model_parameters/'+value, help='location of model checkpoints')\n",
    "parser.add_argument('--label_len', type=int, default=int(24*7) , help='start token length of Informer decoder')\n",
    "parser.add_argument('--pred_len', type=int, default=24, help='prediction sequence length')\n",
    "\n",
    "parser.add_argument('--d_model', type=int, default=256, help='dimension of model')\n",
    "parser.add_argument('--num_workers', type=int, default=8, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=20, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-4, help='optimizer learning rate')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='none, type1, type2')\n",
    "parser.add_argument('--inverse', action='store_true', help='inverse output data', default=False)\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3',help='device ids of multile gpus')\n",
    "parser.add_argument('--n_times', type=int, default=100, help='diffusion steps')\n",
    "parser.add_argument('--sampling', type=bool, default=False, help='sampling of outcomes')\n",
    "parser.add_argument('--sampling_times', type=int, default=30, help='number of outcomes')\n",
    "parser.add_argument('--train_est', type=bool, default=False , help='train estimator')\n",
    "parser.add_argument('--offset', type=bool, default=False, help='offset of the output')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed(42)  # Replace 42 with your desired seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(model='IL_DiffTSF', data='ETTh1', root_path='/home/uservan/Desktop/TS_Diff/datasets', data_path='ETTh1.csv', features='M', target='OT', freq='1H', checkpoints='model_parameters/ETTh1', label_len=168, pred_len=24, d_model=256, num_workers=8, itr=1, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, lradj='type1', inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', n_times=100, sampling=False, sampling_times=30, train_est=False, offset=False, enc_in=7, dec_in=7, c_out=7, detail_freq='1H', lambdareg=100)\n",
      "168\n",
      "24\n",
      "Use GPU: cuda:0\n",
      "Trainable Parameters:2690137\n",
      "Trainable Parameters:286727\n",
      ">>>>>>>start training IL_DiffTSF_168_24_dETTh1_ftM_ll168_pl24_dm256_n_times_100_ii_100_OF_False>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12003\n",
      "val 1551\n",
      "No File, Train new\n",
      "No EST File, Train new\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc7fac3930b40c8951155fb23791e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "Exp = Exp_IL_DiffTSF\n",
    "def runtrain(args):\n",
    "        mae_list=[]\n",
    "        crps_list=[]\n",
    "        mse_list=[]\n",
    "        index =args.model +\"_\"+str(args.label_len)+\"_\"+str(args.pred_len)\n",
    "        resultsMAE,resultsCRPS,resultsMSE=[],[],[]\n",
    "        mae_list=[]\n",
    "        crps_list,mse_list=[],[]\n",
    "        for ii in range(args.itr):\n",
    "               \n",
    "                # setting record of experiments\n",
    "                setting = '{}_d{}_ft{}_ll{}_pl{}_dm{}_n_times_{}_ii_{}_OF_{}'.format(\n",
    "                        index, args.data, args.features,args.label_len, args.pred_len,\n",
    "                        args.d_model,args.n_times,args.reg,args.offset)\n",
    "                \n",
    "                exp = Exp(args) # set experiments\n",
    "                print('>>>>>>>start training {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "                exp.train(setting)\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                resultout,crpsret=exp.test(setting,True)\n",
    "\n",
    "                mae,mse,rmse,mspe,shape =resultout\n",
    "\n",
    "                print(setting)\n",
    "                mse_list.append(mse)\n",
    "                mse_np=np.array(mse_list)\n",
    "                mae_list.append(mae)\n",
    "                mae_np=np.array(mae_list)\n",
    "                crps_list.append(np.mean(crpsret))\n",
    "                crps_np=np.array(crps_list)\n",
    "        \n",
    "                print(\"predlen:\"+str(args.pred_len)+\",CRPS_L:\"+str(len(crps_np))+\",AVE:\"+str(np.round(np.mean(crps_np),3))+\"±\"+str(np.round(np.std(crps_np),4)))\n",
    "                print(\"predlen:\"+str(args.pred_len)+\",MSE_L:\"+str(len(mse_np))+\",AVE:\"+str(np.round(np.mean(mse_np),3))+\"±\"+str(np.round(np.std(mse_np),4)))\n",
    "                print(\"predlen:\"+str(args.pred_len)+\",MAE_L:\"+str(len(mae_np))+\",AVE:\"+str(np.round(np.mean(mae_np),3))+\"±\"+str(np.round(np.std(mae_np),4)))\n",
    "                resultsCRPS.append(str(ii)+\"_\"+\"predlen:\"+str(args.pred_len)+\",CRPS_L:\"+str(len(crps_np))+\",AVE:\"+str(np.round(np.mean(crps_np),3))+\"±\"+str(np.round(np.std(crps_np),4)))\n",
    "                resultsMSE.append(str(ii)+\"_\"+\"predlen:\"+str(args.pred_len)+\",MSE_L:\"+str(len(mse_np))+\",AVE:\"+str(np.round(np.mean(mse_np),3))+\"±\"+str(np.round(np.std(mse_np),4)))\n",
    "                resultsMAE.append(str(ii)+\"_\"+\"predlen:\"+str(args.pred_len)+\",MAE_L:\"+str(len(mae_np))+\",AVE:\"+str(np.round(np.mean(mae_np),3))+\"±\"+str(np.round(np.std(mae_np),4)))\n",
    "                f= open(os.path.abspath('')+\"/results/\"+str(args.data)+\"/\"+str(args.pred_len)+\"_d_ff\"+str(args.d_model)+\"_ntimes\"+str(args.n_times)+\"_\"+str(args.data)+\"_\"+str(args.reg)+\"_f\"+str(args.features)+\"_condk\"+str(args.condk)+\".txt\",\"w+\")\n",
    "                f.write(str(setting)+\"\\n\"+str(resultsCRPS) +\"\\n\"+str(resultsMSE)+\"\\n\"+str(resultsMAE))\n",
    "                f.close()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        return str(np.round(np.mean(mae_np),3))\n",
    "\n",
    "dataname='ETTh1'\n",
    "args.data =dataname\n",
    "args.checkpoints='model_parameters/'+dataname\n",
    "\n",
    "data_parser = {\n",
    "'exchange':{'data':'exchange_all.csv','T':'OT','M':[8,8,8],'S':[1,1,1],'MS':[8,8,1],'freqin':'1D'},\n",
    "'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'1H'},\n",
    "'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'1H'},\n",
    "'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'1H'},\n",
    "'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1],'freqin':'15min'},\n",
    "'weather':{'data':'weather.csv','T':'OT','M':[12,12,12],'S':[1,1,1],'MS':[12,12,1],'freqin':'1H'},\n",
    "'electrans':{'data':'electrans.csv','T':'OT','M':[32,32,32],'S':[1,1,1],'MS':[321,321,1],'freqin':'1H'},\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "        data_info = data_parser[args.data]\n",
    "        args.data_path = data_info['data']\n",
    "        args.target = data_info['T']\n",
    "        args.enc_in, args.dec_in, args.c_out = data_info[args.features]\n",
    "        args.freq=data_info['freqin']\n",
    "\n",
    "args.detail_freq = args.freq\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "for i in range(0,5):\n",
    "        torch.cuda.empty_cache()\n",
    "        args.d_model=256\n",
    "        args.reg=100\n",
    "        args.n_times=100\n",
    "        items= [[168,24],[168,96],[336,168],[720,336]] #for ETTh1\n",
    "        args.batch_size=32\n",
    "        args.label_len =items[i][0]\n",
    "        args.pred_len =items[i][1]\n",
    "        print(args.label_len)\n",
    "        print(args.pred_len)\n",
    "        runtrain(args)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNYamTAUmYDsZgII9uXX8CT",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1bcfz1OsVbD2yCIk1zcleV5paW0iaFtTg",
   "name": "",
   "version": ""
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "60461829a35a4f24414f6b9a81cb167855ac5d995cbf4b4b96212d9b44c21eb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
